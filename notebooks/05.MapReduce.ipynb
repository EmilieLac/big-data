{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Map\n",
    "\n",
    "![domain decomposition](https://computing.llnl.gov/tutorials/parallel_comp/images/domain_decomp.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## `map` function example\n",
    "\n",
    "The `map(func, seq)` Python function applies the function func to all the elements of the sequence seq. It returns a new list with the elements changed by func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x * x\n",
    "\n",
    "rdd = [2, 6, -3, 7]\n",
    "res = map(f, rdd )\n",
    "res  # Res is an iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(*res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from operator import mul\n",
    "rdd1, rdd2 = [2, 6, -3, 7], [1, -4, 5, 3]\n",
    "res = map(mul, rdd1, rdd2 ) # element wise sum of rdd1 and rdd2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(*res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reduce\n",
    "\n",
    "![MapReduce](http://mm-tom.s3.amazonaws.com/blog/MapReduce.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `functools.reduce` example\n",
    "\n",
    "The function `reduce(func, seq)` continually applies the function func() to the sequence seq and return a single value. For example, reduce(f, [1, 2, 3, 4, 5]) calculates f(f(f(f(1,2),3),4),5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from operator import add\n",
    "\n",
    "reduce(mul, rdd) # computes ((((1+2)+3)+4)+5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "p = 1\n",
    "for x in rdd:\n",
    "    p *= x\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def g(x,y):\n",
    "    return x * y\n",
    "\n",
    "reduce(g, rdd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "p = 1\n",
    "for x in rdd:\n",
    "    p *= x\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Weighted mean and Variance\n",
    "\n",
    "If the generator of random variable $X$ is discrete with probability mass function $x_1 \\mapsto p_1, x_2 \\mapsto p_2, \\ldots, x_n \\mapsto p_n$ then\n",
    "\n",
    "$$\\operatorname{Var}(X) = \\left(\\sum_{i=1}^n p_i x_i ^2\\right) - \\mu^2,$$\n",
    "\n",
    "where $\\mu$ is the average value, i.e.\n",
    "\n",
    "$$\\mu = \\sum_{i=1}^n p_i x_i. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X = [5, 1, 2, 3, 1, 2, 5, 4]\n",
    "P = [0.05, 0.05, 0.15, 0.05, 0.15, 0.2, 0.1, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, p in zip(X, P):\n",
    "    print(f\" x = {x} ..... p = {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest, cycle\n",
    "\n",
    "for x, p in zip_longest(X, [0.1], fillvalue=0.0):\n",
    "    print(f\" x = {x} ..... p = {p}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Exercise 5.1\n",
    "\n",
    "- Write functions to compute the average value and variance using for loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean( X, P):\n",
    "    return sum([x*p for x, p in zip(X,P)])\n",
    "\n",
    "weighted_mean(X,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(X, P):\n",
    "    mu = weighted_mean(X,P)\n",
    "    return sum([p*x*x for x,p in zip(X,P)]) - mu**2\n",
    "\n",
    "variance(X, P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Exercise 5.2\n",
    "\n",
    "- Write functions to compute the average value and variance using `map` and `reduce`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add, mul\n",
    "from functools import reduce\n",
    "\n",
    "def weighted_mean( X, P):\n",
    "    return reduce(add,map(mul, X, P))\n",
    "\n",
    "weighted_mean(X,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(X, P):\n",
    "    mu = weighted_mean(X,P)\n",
    "    return reduce(add,map(lambda x,p:p*x*x, X, P)) - mu**2\n",
    "\n",
    "variance(X, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = filter( lambda p: p > 0.1, P)\n",
    "print(*res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = filter( lambda x: x % 3 == 0, range(15))\n",
    "print(*res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*NB: Exercises above are just made to help to understand map-reduce process.\n",
    "This is a bad way to code a variance in Python. You should use [Numpy](http://www.numpy.org) instead.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Wordcount \n",
    "\n",
    "We will modify the `wordcount` application into a map-reduce process.\n",
    "\n",
    "The `map` process takes text files as input and breaks it into words. The `reduce`  process sums the counts for each word and emits a single key/value with the word and sum.\n",
    "\n",
    "We need to split the wordcount function we wrote in notebook 04 in order to use map and reduce. \n",
    "\n",
    "In the following exercices we will implement in Python the Java example described in [Hadoop documentation](https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html#Example:_WordCount_v1.0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Map \n",
    "\n",
    "## Read file and return a key/value pairs\n",
    "\n",
    "### Exercise 5.3\n",
    "\n",
    "Write a function `mapper` with a single file name as input that returns a sorted sequence of tuples (word, 1) values.\n",
    "\n",
    "```pybt\n",
    "mapper('sample.txt')\n",
    "[('adipisci', 1), ('adipisci', 1), ('adipisci', 1), ('adipisci', 1), ('adipisci', 1), ('adipisci', 1), ('adipisci', 1), ('aliquam', 1), ('aliquam', 1), ('aliquam', 1), ('aliquam', 1), ('aliquam', 1), ('aliquam', 1), ('aliquam', 1), ('amet', 1), ('amet', 1), ('amet', 1)...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lorem\n",
    "with open('sample.txt','w') as f:\n",
    "    f.write(lorem.text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(filename):\n",
    "    with open(filename) as f:\n",
    "        data = f.read()\n",
    "        \n",
    "    data = data.strip().replace(\".\",\"\").lower().split()\n",
    "        \n",
    "    return sorted([(w,1) for w in data])\n",
    "\n",
    "mapper(\"sample.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition\n",
    "\n",
    "### Exercise 5.4\n",
    "\n",
    "Create a function named `partitioner` that stores the key/value pairs from `mapper`  that group (word, 1) pairs into a list as:\n",
    "```python\n",
    "partitioner(mapper('sample.txt'))\n",
    "[('adipisci', [1, 1, 1, 1, 1, 1, 1]), ('aliquam', [1, 1, 1, 1, 1, 1, 1]), ('amet', [1, 1, 1, 1],...]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def partitioner(mapped_values):\n",
    "    \n",
    "    res = defaultdict(list)\n",
    "    for w, c in mapped_values:\n",
    "        res[w].append(c)\n",
    "        \n",
    "    return res.items()\n",
    "\n",
    "\n",
    "partitioner(mapper('sample.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reduce \n",
    "\n",
    "## Sums the counts and returns a single key/value (word, sum).\n",
    "\n",
    "### Exercice 5.5\n",
    "\n",
    "Write the function `reducer` that read a tuple (word,[1,1,1,..,1]) and sum the occurrences of word to a final count, and then output the tuple (word,occurences).\n",
    "\n",
    "```python\n",
    "reducer(('hello',[1,1,1,1,1])\n",
    "('hello',5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hello', 5)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "def reducer( item ):\n",
    "    w, v = item\n",
    "    return (w,len(v))\n",
    "\n",
    "reducer(('hello',[1,1,1,1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Process several files\n",
    "\n",
    "Let's create 8 files `sample[0-7].txt`. Set most common words at the top of the output list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from lorem import text\n",
    "for i in range(8):\n",
    "    with open(\"sample{0:02d}.txt\".format(i), \"w\") as f:\n",
    "        f.write(text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample00.txt',\n",
       " 'sample01.txt',\n",
       " 'sample02.txt',\n",
       " 'sample03.txt',\n",
       " 'sample04.txt',\n",
       " 'sample05.txt',\n",
       " 'sample06.txt',\n",
       " 'sample07.txt']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "files = sorted(glob.glob('sample0*.txt'))\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 5.6\n",
    "- Use functions implemented above to count (word, occurences) by using a for loops over files and partitioned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def wordcount(files):\n",
    "    \n",
    "    mapped_values = [mapper(file) for file in files]\n",
    "    \n",
    "    partioned_values = partitioner(chain(*mapped_values))\n",
    "            \n",
    "    return sorted([reducer(val) for val in partioned_values],\n",
    "                  key = itemgetter(1),\n",
    "                  reverse = True)\n",
    "\n",
    "wordcount(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 5.7\n",
    "- This time use `map` function to apply mapper and reducer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('voluptatem', 69),\n",
       " ('amet', 67),\n",
       " ('sit', 66),\n",
       " ('dolorem', 65),\n",
       " ('non', 61),\n",
       " ('quisquam', 60),\n",
       " ('sed', 59),\n",
       " ('adipisci', 55),\n",
       " ('consectetur', 55),\n",
       " ('magnam', 54),\n",
       " ('velit', 54),\n",
       " ('est', 53),\n",
       " ('ipsum', 53),\n",
       " ('neque', 53),\n",
       " ('numquam', 53),\n",
       " ('eius', 52),\n",
       " ('quaerat', 52),\n",
       " ('tempora', 50),\n",
       " ('dolor', 49),\n",
       " ('dolore', 48),\n",
       " ('etincidunt', 48),\n",
       " ('modi', 47),\n",
       " ('aliquam', 45),\n",
       " ('porro', 45),\n",
       " ('quiquia', 45),\n",
       " ('labore', 42),\n",
       " ('ut', 42)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wordcount(files):\n",
    "    \n",
    "    mapped_values = map(mapper, files)\n",
    "    partioned_values = partitioner(chain(*mapped_values))\n",
    "    \n",
    "    return sorted( map(reducer, partioned_values),\n",
    "                 key=itemgetter(1),\n",
    "                 reverse=True)\n",
    "    \n",
    "    \n",
    "wordcount(files)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
