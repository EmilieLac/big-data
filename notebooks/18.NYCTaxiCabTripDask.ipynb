{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask dataframes on HDFS\n",
    "\n",
    "To use Dask dataframes in parallel across an HDFS cluster to read CSV data. We can coordinate these computations with [distributed](http://distributed.dask.org/en/latest/) and dask.dataframe.\n",
    "\n",
    "As Spark, Dask can work in cluster mode. To start, we connect to our scheduler, import the hdfs module from the distributed library, and read our CSV data from HDFS.\n",
    "\n",
    "```python\n",
    "import dask.dataframe as dd\n",
    "from distributed import Client, progress\n",
    "import os\n",
    "\n",
    "c = Client(\"svmass2.mass.uhb.fr:8786\")\n",
    "c\n",
    "```\n",
    "A Dashboard is available at http://svmass2.mass.uhb.fr:8787/status\n",
    "\n",
    "`nyc2014` is a dask.dataframe objects which present a subset of the Pandas API to the user, but farm out all of the work to the many Pandas dataframes they control across the network.\n",
    "\n",
    "```python\n",
    "nyc2014 = dd.read_csv('hdfs://svmass2.mass.uhb.fr:54310/user/datasets/nyc-tlc/2014/yellow*.csv',\n",
    "parse_dates=['pickup_datetime', 'dropoff_datetime'],\n",
    "skipinitialspace=True)\n",
    "nyc2014 = c.persist(nyc2014)\n",
    "progress(nyc2014)\n",
    "```\n",
    "\n",
    "*Unfortunately the Dask cluster does not work. There is an installation error i can't find. \n",
    "dask workers can't read the csv files on HDFS.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise \n",
    "\n",
    "- Use parquet file you created with Spark and load it into a Dask Dataframe\n",
    "- Display head of the dataframe\n",
    "- Display number of rows of this dataframe.\n",
    "- Compute the total number of passengers.\n",
    "- Count occurrences in the payment_type column both for the full dataset, and filtered by zero tip (tip_amount == 0).\n",
    "- Create a new column, tip_fraction\n",
    "- Plot the average of the new column tip_fraction grouped by day of week.\n",
    "- Plot the average of the new column tip_fraction grouped by hour of day.\n",
    "\n",
    "[Dask dataframe documentation](http://docs.dask.org/en/latest/dataframe.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://svmass2.mass.uhb.fr:8786\n",
       "  <li><b>Dashboard: </b><a href='http://svmass2.mass.uhb.fr:8787/status' target='_blank'>http://svmass2.mass.uhb.fr:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>24</li>\n",
       "  <li><b>Cores: </b>96</li>\n",
       "  <li><b>Memory: </b>138.73 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://192.168.2.54:8786' processes=24 cores=96>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from distributed import Client, progress\n",
    "import os\n",
    "\n",
    "c = Client(\"svmass2.mass.uhb.fr:8786\")\n",
    "c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408dec74eba94d5c8abaae8e2bed4f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nyc2014 = dd.read_csv('hdfs://svmass2.mass.uhb.fr:54310/user/datasets/nyc-tlc/2014/yellow*.csv',\n",
    "parse_dates=['pickup_datetime', 'dropoff_datetime'],\n",
    "skipinitialspace=True)\n",
    "nyc2014 = c.persist(nyc2014)\n",
    "progress(nyc2014)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (big-data)",
   "language": "python",
   "name": "big-data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
