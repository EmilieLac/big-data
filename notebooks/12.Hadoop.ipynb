{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Big Data\n",
    "\n",
    "- Data sets that are so large or complex that traditional data processing application software is inadequate to deal with them. \n",
    "- Data analysis requires massively parallel software running on several servers.\n",
    "- **Volume, Variety, Velocity, Variability and Veracity** describe Big Data properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![https://github.com/veekaybee/data-lake-talk/](images/bigdata.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Hadoop Logo](images/hadoop.png)\n",
    "\n",
    "- Framework for running applications on large cluster. \n",
    "- The Hadoop framework transparently provides applications both reliability and data motion. \n",
    "- Hadoop implements the computational paradigm named **Map/Reduce**, where the application is divided into many small fragments of work, each of which may be executed or re-executed on any node in the cluster. \n",
    "- It provides a distributed file system (HDFS) that stores data on the compute nodes, providing very high aggregate bandwidth across the cluster.\n",
    "- Both MapReduce and the **Hadoop Distributed File System** are designed so that node failures are automatically handled by the framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# HDFS\n",
    "* It is a distributed file systems.\n",
    "* HDFS is highly fault-tolerant and is designed to be deployed on low-cost hardware.\n",
    "* HDFS is suitable for applications that have large data sets. \n",
    "* HDFS provides interfaces to move applications closer to where the data is located. The computation is much more efficient when the size of the data set is huge. \n",
    "* HDFS consists of a single NameNode with a number of DataNodes which manage storage. \n",
    "* HDFS exposes a file system namespace and allows user data to be stored in files. \n",
    "    1. A file is split by the NameNode into blocks stored in DataNodes. \n",
    "    2. The **NameNode** executes operations like opening, closing, and renaming files and directories.\n",
    "    3. The **Secondary NameNode** stores information from **NameNode**. \n",
    "    4. The **DataNodes** manage perform block creation, deletion, and replication upon instruction from the NameNode.\n",
    "    5. The placement of replicas is optimized for data reliability, availability, and network bandwidth utilization.\n",
    "    6. User data never flows through the NameNode.\n",
    "* Files in HDFS are write-once and have strictly one writer at any time.\n",
    "* The DataNode has no knowledge about HDFS files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Accessibility\n",
    "\n",
    "All [HDFS commands](http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/FileSystemShell.html)  are invoked by the bin/hdfs Java script:\n",
    "```shell\n",
    "hdfs [SHELL_OPTIONS] COMMAND [GENERIC_OPTIONS] [COMMAND_OPTIONS]\n",
    "```\n",
    "## Manage files and directories\n",
    "```shell\n",
    "hdfs dfs -ls -h -R # Recursively list subdirectories with human-readable file sizes.\n",
    "hdfs dfs -cp  # Copy files from source to destination\n",
    "hdfs dfs -mv  # Move files from source to destination\n",
    "hdfs dfs -mkdir /foodir # Create a directory named /foodir\t\n",
    "hdfs dfs -rmr /foodir   # Remove a directory named /foodir\t\n",
    "hdfs dfs -cat /foodir/myfile.txt #View the contents of a file named /foodir/myfile.txt\t\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transfer between nodes\n",
    "\n",
    "## put\n",
    "```shell\n",
    "hdfs fs -put [-f] [-p] [-l] [-d] [ - | <localsrc1> .. ]. <dst>\n",
    "```\n",
    "Copy single src, or multiple srcs from local file system to the destination file system. \n",
    "\n",
    "Options:\n",
    "\n",
    "    -p : Preserves rights and modification times.\n",
    "    -f : Overwrites the destination if it already exists.\n",
    "\n",
    "```shell\n",
    "hdfs fs -put localfile /user/hadoop/hadoopfile\n",
    "hdfs fs -put -f localfile1 localfile2 /user/hadoop/hadoopdir\n",
    "```\n",
    "Similar to the fs -put command\n",
    "- `moveFromLocal` : to delete the source localsrc after copy.\n",
    "- `copyFromLocal` : source is restricted to a local file\n",
    "- `copyToLocal` : destination is restricted to a local file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![hdfs blocks](images/hdfs-fonctionnement.jpg)\n",
    "\n",
    "The Name Node is not in the data path. The Name Node only provides the map of where data is and where data should go in the cluster (file system metadata)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cluster Hadoop\n",
    "\n",
    "- 8 computers: UC7173 -> UC7188\n",
    "\n",
    "### NameNode Web Interface (HDFS layer) \n",
    "\n",
    "http://svmass2.mass.uhb.fr:50070\n",
    "\n",
    "The name node web UI shows you a cluster summary including information about total/remaining capacity, live and dead nodes. Additionally, it allows you to browse the HDFS namespace and view the contents of its files in the web browser. It also gives access to the local machineâ€™s Hadoop log files.\n",
    "\n",
    "### Secondary Namenode Information.\n",
    "\n",
    "http://svmass2.mass.uhb.fr:50090/\n",
    "\n",
    "### Datanode Information.\n",
    "\n",
    "- http://uc7173.mass.uhb.fr:50075/\n",
    "- http://uc7174.mass.uhb.fr:50075/\n",
    "- ...\n",
    "- http://uc7187.mass.uhb.fr:50075/\n",
    "- http://uc7188.mass.uhb.fr:50075/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To do following hands on you can switch to [JupyterLab](https://jupyterlab.readthedocs.io).\n",
    "\n",
    "Just go to this following address http://localhost:9000/lab\n",
    "\n",
    "- Check that your HDFS home directory required to execute MapReduce jobs exists:\n",
    "```bash\n",
    "hdfs dfs -ls /user/${USER}\n",
    "```\n",
    "- Type the following commands: \n",
    "```bash\n",
    "hdfs dfs -ls\n",
    "hdfs dfs -ls /\n",
    "hdfs dfs -mkdir test\n",
    "```\n",
    "- Create a local file user.txt containing your name and the date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pierre Navaro\n",
      "Fri Sep 21 15:26:14 CEST 2018\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"Pierre Navaro\" > user.txt\n",
    "echo `date` >> user.txt \n",
    "cat user.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Copy it on  HDFS :\n",
    "```bash\n",
    "hdfs dfs -put user.txt\n",
    "```\n",
    "\n",
    "Check with:\n",
    "```bash\n",
    "hdfs dfs -ls -R \n",
    "hdfs dfs -cat user.txt \n",
    "hdfs dfs -tail user.txt \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x   - navaro_p hadoop          0 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop          0 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/_SUCCESS\n",
      "-rw-r--r--   4 navaro_p hadoop       1978 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/_common_metadata\n",
      "-rw-r--r--   4 navaro_p hadoop     490581 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/_metadata\n",
      "-rw-r--r--   4 navaro_p hadoop   16649704 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00000-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14980896 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00001-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13785646 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00002-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14443612 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00003-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14533801 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00004-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13769459 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00005-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13227234 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00006-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14400875 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00007-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14351039 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00008-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14572172 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00009-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14166352 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00010-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   12995642 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00011-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14657121 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00012-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13409176 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00013-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13037003 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00014-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13247576 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00015-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15301939 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00016-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13908955 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00017-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13327420 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00018-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   12976855 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00019-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   12837348 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00020-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14380952 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00021-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13960101 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00022-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13834174 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00023-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13905225 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00024-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13609492 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00025-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13180315 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00026-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   12854827 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00027-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14293135 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00028-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13917755 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00029-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13923210 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00030-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   12981866 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00031-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14688496 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00032-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14094788 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00033-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14787698 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00034-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14769868 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00035-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13590000 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00036-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13390240 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00037-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14110020 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00038-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   12828757 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00039-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13631852 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00040-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14131567 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00041-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14952241 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00042-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14624181 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00043-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13553377 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00044-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13300229 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00045-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13793190 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00046-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14105054 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00047-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14357239 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00048-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14608425 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00049-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13193640 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00050-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13762144 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00051-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13773351 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00052-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14217392 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00053-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15125924 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00054-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13993234 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00055-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14839572 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00056-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13789028 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00057-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13928546 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00058-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13337725 2018-09-20 21:06 /user/navaro_p/2016-yellow.parquet/part-00059-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14211093 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00060-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   12915717 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00061-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13962774 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00062-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14247302 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00063-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14239317 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00064-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13854363 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00065-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14470286 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00066-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13253124 2018-09-20 21:06 /user/navaro_p/2016-yellow.parquet/part-00067-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14291418 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00068-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14389134 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00069-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14313707 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00070-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13733728 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00071-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14318195 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00072-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14460636 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00073-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14127336 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00074-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14631134 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00075-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13322302 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00076-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14367893 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00077-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13582077 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00078-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15604501 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00079-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13227721 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00080-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13113212 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00081-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14202658 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00082-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14356504 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00083-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14809109 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00084-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14556087 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00085-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13125212 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00086-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14436072 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00087-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14481522 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00088-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13942644 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00089-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14728880 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00090-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13534181 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00091-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14431803 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00092-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13140061 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00093-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14980599 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00094-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15080286 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00095-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14532058 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00096-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14581802 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00097-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15593187 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00098-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14709117 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00099-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13457417 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00100-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14696458 2018-09-20 21:06 /user/navaro_p/2016-yellow.parquet/part-00101-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15137647 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00102-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15284594 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00103-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13617451 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00104-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14023820 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00105-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13896260 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00106-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13566967 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00107-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14071337 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00108-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13490478 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00109-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14731612 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00110-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15660461 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00111-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14078129 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00112-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14505350 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00113-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14914863 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00114-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13152079 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00115-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14690660 2018-09-20 21:06 /user/navaro_p/2016-yellow.parquet/part-00116-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   14341579 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00117-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   16011888 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00118-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15759600 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00119-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15572907 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00120-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15734269 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00121-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15969822 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00122-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15865088 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00123-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15853654 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00124-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15534909 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00125-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15817112 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00126-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   16207894 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00127-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15856964 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00128-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   16198877 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00129-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15937869 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00130-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15252144 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00131-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15616957 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00132-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15221287 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00133-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15453132 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00134-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15668332 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00135-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15379551 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00136-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15854588 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00137-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15649378 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00138-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15888462 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00139-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15558170 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00140-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15551656 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00141-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15622100 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00142-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15745601 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00143-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15583126 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00144-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15384571 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00145-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15389287 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00146-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15514161 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00147-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15504629 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00148-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15413234 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00149-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15533935 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00150-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15425277 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00151-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15119903 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00152-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15371435 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00153-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15223799 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00154-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15505309 2018-09-20 21:06 /user/navaro_p/2016-yellow.parquet/part-00155-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15339455 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00156-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15446079 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00157-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15302004 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00158-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15280129 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00159-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15267021 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00160-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15399422 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00161-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15524851 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00162-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15354478 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00163-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15411266 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00164-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15534078 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00165-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15502578 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00166-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15216450 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00167-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15354844 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00168-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15348905 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00169-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15241814 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00170-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15549971 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00171-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15229734 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00172-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15387764 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00173-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15219068 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00174-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15857340 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00175-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15421559 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00176-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   15457672 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00177-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   13769237 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00178-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   12168148 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00179-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   11973095 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00180-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   10040172 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00181-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop    6619192 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00182-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   12660058 2018-09-20 21:08 /user/navaro_p/2016-yellow.parquet/part-00183-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop   11584085 2018-09-20 21:07 /user/navaro_p/2016-yellow.parquet/part-00184-99cc3aaa-6528-4357-a432-8350ba046c60-c000.snappy.parquet\n",
      "drwxr-xr-x   - navaro_p hadoop          0 2018-09-14 15:56 /user/navaro_p/daily-stock\n",
      "-rw-r--r--   4 navaro_p hadoop    9229680 2018-09-14 12:21 /user/navaro_p/daily-stock/aet.h5\n",
      "-rw-r--r--   4 navaro_p hadoop    7043530 2018-09-14 15:55 /user/navaro_p/daily-stock/aet.json\n",
      "-rw-r--r--   4 navaro_p hadoop    9229680 2018-09-14 12:21 /user/navaro_p/daily-stock/afl.h5\n",
      "-rw-r--r--   4 navaro_p hadoop    7043232 2018-09-14 15:55 /user/navaro_p/daily-stock/afl.json\n",
      "-rw-r--r--   4 navaro_p hadoop    9229680 2018-09-14 12:21 /user/navaro_p/daily-stock/aig.h5\n",
      "-rw-r--r--   4 navaro_p hadoop    7044036 2018-09-14 15:55 /user/navaro_p/daily-stock/aig.json\n",
      "-rw-r--r--   4 navaro_p hadoop    9229680 2018-09-14 12:21 /user/navaro_p/daily-stock/al.h5\n",
      "-rw-r--r--   4 navaro_p hadoop    7040315 2018-09-14 15:55 /user/navaro_p/daily-stock/al.json\n",
      "-rw-r--r--   4 navaro_p hadoop    9229680 2018-09-14 12:21 /user/navaro_p/daily-stock/amgn.h5\n",
      "-rw-r--r--   4 navaro_p hadoop    7351490 2018-09-14 15:55 /user/navaro_p/daily-stock/amgn.json\n",
      "-rw-r--r--   4 navaro_p hadoop    9229680 2018-09-14 12:21 /user/navaro_p/daily-stock/avy.h5\n",
      "-rw-r--r--   4 navaro_p hadoop    7042746 2018-09-14 15:55 /user/navaro_p/daily-stock/avy.json\n",
      "-rw-r--r--   4 navaro_p hadoop    9229680 2018-09-14 12:21 /user/navaro_p/daily-stock/b.h5\n",
      "-rw-r--r--   4 navaro_p hadoop    7036586 2018-09-14 15:55 /user/navaro_p/daily-stock/b.json\n",
      "-rw-r--r--   4 navaro_p hadoop    9229680 2018-09-14 12:21 /user/navaro_p/daily-stock/bwa.h5\n",
      "-rw-r--r--   4 navaro_p hadoop    7044883 2018-09-14 15:56 /user/navaro_p/daily-stock/bwa.json\n",
      "-rw-r--r--   4 navaro_p hadoop    9229680 2018-09-14 12:22 /user/navaro_p/daily-stock/ge.h5\n",
      "-rw-r--r--   4 navaro_p hadoop    7039466 2018-09-14 15:56 /user/navaro_p/daily-stock/ge.json\n",
      "-rw-r--r--   4 navaro_p hadoop    9229680 2018-09-14 12:22 /user/navaro_p/daily-stock/hal.h5\n",
      "-rw-r--r--   4 navaro_p hadoop    7045860 2018-09-14 15:56 /user/navaro_p/daily-stock/hal.json\n",
      "-rw-r--r--   4 navaro_p hadoop    9229680 2018-09-14 12:22 /user/navaro_p/daily-stock/hp.h5\n",
      "-rw-r--r--   4 navaro_p hadoop    7151338 2018-09-14 15:56 /user/navaro_p/daily-stock/hp.json\n",
      "-rw-r--r--   4 navaro_p hadoop    9229680 2018-09-14 12:22 /user/navaro_p/daily-stock/hpq.h5\n",
      "-rw-r--r--   4 navaro_p hadoop    7044048 2018-09-14 15:56 /user/navaro_p/daily-stock/hpq.json\n",
      "-rw-r--r--   4 navaro_p hadoop    9229680 2018-09-14 12:22 /user/navaro_p/daily-stock/ibm.h5\n",
      "-rw-r--r--   4 navaro_p hadoop    7349542 2018-09-14 15:56 /user/navaro_p/daily-stock/ibm.json\n",
      "-rw-r--r--   4 navaro_p hadoop    9229680 2018-09-14 12:22 /user/navaro_p/daily-stock/jbl.h5\n",
      "-rw-r--r--   4 navaro_p hadoop    7044189 2018-09-14 15:56 /user/navaro_p/daily-stock/jbl.json\n",
      "-rw-r--r--   4 navaro_p hadoop    9229680 2018-09-14 12:22 /user/navaro_p/daily-stock/jpm.h5\n",
      "-rw-r--r--   4 navaro_p hadoop    7045855 2018-09-14 15:56 /user/navaro_p/daily-stock/jpm.json\n",
      "-rw-r--r--   4 navaro_p hadoop    9229680 2018-09-14 12:22 /user/navaro_p/daily-stock/luv.h5\n",
      "-rw-r--r--   4 navaro_p hadoop    7044192 2018-09-14 15:56 /user/navaro_p/daily-stock/luv.json\n",
      "-rw-r--r--   4 navaro_p hadoop    9229680 2018-09-14 12:22 /user/navaro_p/daily-stock/met.h5\n",
      "-rw-r--r--   4 navaro_p hadoop    7044020 2018-09-14 15:56 /user/navaro_p/daily-stock/met.json\n",
      "-rw-r--r--   4 navaro_p hadoop    9229680 2018-09-14 12:22 /user/navaro_p/daily-stock/pcg.h5\n",
      "-rw-r--r--   4 navaro_p hadoop    7040636 2018-09-14 15:56 /user/navaro_p/daily-stock/pcg.json\n",
      "-rw-r--r--   4 navaro_p hadoop    9229680 2018-09-14 12:22 /user/navaro_p/daily-stock/tgt.h5\n",
      "-rw-r--r--   4 navaro_p hadoop    7044043 2018-09-14 15:56 /user/navaro_p/daily-stock/tgt.json\n",
      "-rw-r--r--   4 navaro_p hadoop    9229680 2018-09-14 12:22 /user/navaro_p/daily-stock/usb.h5\n",
      "-rw-r--r--   4 navaro_p hadoop    7041875 2018-09-14 15:56 /user/navaro_p/daily-stock/usb.json\n",
      "-rw-r--r--   4 navaro_p hadoop  102073069 2018-09-14 12:22 /user/navaro_p/daily-stock/xom.h5\n",
      "-rw-r--r--   4 navaro_p hadoop    7109906 2018-09-14 15:56 /user/navaro_p/daily-stock/xom.json\n",
      "drwxr-xr-x   - navaro_p hadoop          0 2018-09-20 17:43 /user/navaro_p/nycflights\n",
      "-rw-r--r--  16 navaro_p hadoop   22611683 2018-09-19 17:10 /user/navaro_p/nycflights/1990.csv\n",
      "-rw-r--r--  16 navaro_p hadoop   21535597 2018-09-19 17:10 /user/navaro_p/nycflights/1991.csv\n",
      "-rw-r--r--  16 navaro_p hadoop   21783667 2018-09-19 17:10 /user/navaro_p/nycflights/1992.csv\n",
      "-rw-r--r--  16 navaro_p hadoop   21495608 2018-09-19 17:10 /user/navaro_p/nycflights/1993.csv\n",
      "-rw-r--r--  16 navaro_p hadoop   21696030 2018-09-19 17:10 /user/navaro_p/nycflights/1994.csv\n",
      "-rw-r--r--  16 navaro_p hadoop   25170054 2018-09-19 17:10 /user/navaro_p/nycflights/1995.csv\n",
      "-rw-r--r--  16 navaro_p hadoop   24979433 2018-09-19 17:10 /user/navaro_p/nycflights/1996.csv\n",
      "-rw-r--r--  16 navaro_p hadoop   24952545 2018-09-19 17:10 /user/navaro_p/nycflights/1997.csv\n",
      "-rw-r--r--  16 navaro_p hadoop   24903801 2018-09-19 17:10 /user/navaro_p/nycflights/1998.csv\n",
      "-rw-r--r--  16 navaro_p hadoop   25952466 2018-09-19 17:11 /user/navaro_p/nycflights/1999.csv\n",
      "-rw-r--r--   4 navaro_p hadoop       2431 2018-09-20 17:43 /user/navaro_p/nycflights/_common_metadata\n",
      "-rw-r--r--   4 navaro_p hadoop      20861 2018-09-20 17:43 /user/navaro_p/nycflights/_metadata\n",
      "-rw-r--r--   4 navaro_p hadoop    4578406 2018-09-20 17:43 /user/navaro_p/nycflights/part.0.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop    4350786 2018-09-20 17:43 /user/navaro_p/nycflights/part.1.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop    4454962 2018-09-20 17:43 /user/navaro_p/nycflights/part.2.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop    4432507 2018-09-20 17:43 /user/navaro_p/nycflights/part.3.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop    4506513 2018-09-20 17:43 /user/navaro_p/nycflights/part.4.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop    6514902 2018-09-20 17:43 /user/navaro_p/nycflights/part.5.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop    6670327 2018-09-20 17:43 /user/navaro_p/nycflights/part.6.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop    6630380 2018-09-20 17:43 /user/navaro_p/nycflights/part.7.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop    6628746 2018-09-20 17:43 /user/navaro_p/nycflights/part.8.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop    6957290 2018-09-20 17:43 /user/navaro_p/nycflights/part.9.parquet\n",
      "-rw-r--r--   4 navaro_p hadoop       1142 2018-09-18 16:01 /user/navaro_p/people.json\n",
      "-rw-r--r--   4 navaro_p hadoop        394 2018-09-18 16:02 /user/navaro_p/people.txt\n",
      "-rw-r--r--   4 navaro_p hadoop         44 2018-09-18 14:11 /user/navaro_p/user.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "put: `.': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hdfs dfs -put /user/navaro_p/user.txt\n",
    "hdfs dfs -ls -R /user/navaro_p/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "hdfs dfs -cat user.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Remove the file:\n",
    "```bash\n",
    "hdfs dfs -rm user.txt\n",
    "```\n",
    "\n",
    "Put it again on HDFS and move to books directory:\n",
    "```bash\n",
    "hdfs dfs -copyFromLocal user.txt\n",
    "hdfs dfs -mv user.txt books/user.txt\n",
    "hdfs dfs -ls -R -h\n",
    "```\n",
    "\n",
    "Copy user.txt to hello.txt and remove it.\n",
    "```bash\n",
    "hdfs dfs -cp books/user.txt books/hello.txt\n",
    "hdfs dfs -count -h /user/$USER\n",
    "hdfs dfs -rm books/user.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on practice:\n",
    "\n",
    "1. Create a directory `files` in HDFS.\n",
    "2. List the contents of a directory /.\n",
    "3. Upload the file today.txt in HDFS.\n",
    "```bash\n",
    "date > today.txt\n",
    "whoami >> today.txt\n",
    "```\n",
    "4. Display contents of file `today.txt`\n",
    "5. Copy `today.txt` file from source to `files` directory.\n",
    "6. Copy file `jps.txt` from/To Local file system to HDFS\n",
    "```bash\n",
    "jps > jps.txt\n",
    "```\n",
    "7. Move file `jps.txt` from source to `files`.\n",
    "8. Remove file `today.txt` from home directory in HDFS.\n",
    "9. Display last few lines of `jps.txt`.\n",
    "10. Display the help of `du` command and show the total amount of space in a human-readable fashion used by your home hdfs directory.\n",
    "12. Display the help of `df` command and show the total amount of space available in the filesystem in a human-readable fashion.\n",
    "13. With `chmod` change the rights of `today.txt` file. I has to be readable and writeable only by you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# YARN\n",
    "\n",
    "*YARN takes care of resource management and job scheduling/monitoring.*\n",
    "\n",
    "- The **ResourceManager** is the ultimate authority that arbitrates resources among all the applications in the system. It has two components: **Scheduler** and **ApplicationsManager**.\n",
    "- The **NodeManager** is the per-machine framework agent who is responsible for **Containers**, monitoring their resource usage (cpu, memory, disk, network) and reporting the same to the **ResourceManager/Scheduler**.\n",
    "\n",
    "The per-application **ApplicationMaster** negotiates resources from the ResourceManager and working with the NodeManager(s) to execute and monitor the tasks.\n",
    "\n",
    "- The **Scheduler** is responsible for allocating resources to the applications.\n",
    "\n",
    "- The **ApplicationsManager** is responsible for accepting job-submissions, tracking their status and monitoring for progress.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Yarn in Hadoop documentation](http://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/yarn_architecture.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Yarn Web Interface\n",
    "\n",
    "The JobTracker web UI provides information about general job statistics of the Hadoop cluster, running/completed/failed jobs and a job history log file. It also gives access to the â€˜â€˜local machineâ€™sâ€™â€™ Hadoop log files (the machine on which the web UI is running on).\n",
    "\n",
    " - All Applications http://svmass2.mass.uhb.fr:8088\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## WordCount Example \n",
    "\n",
    "The [Worcount example](https://wiki.apache.org/hadoop/WordCount) is implemented in Java and it is the example of [Hadoop MapReduce Tutorial](https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html)\n",
    "\n",
    "Let's create some files with lorem python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from lorem import text\n",
    "\n",
    "for i in range(1,10):\n",
    "    with open('sample{0:02d}.txt'.format(i), 'w') as f:\n",
    "        f.write(text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Make input directory in your HDFS home directory required to execute MapReduce jobs:\n",
    "```bash\n",
    "hdfs dfs -mkdir -p /user/${USER}/input\n",
    "```\n",
    "\n",
    "`-p` flag force the directory creation even if it already exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise\n",
    "\n",
    "- Copy all necessary files in HDFS system.\n",
    "- Run the Java example using the command\n",
    "\n",
    "```bash\n",
    "hadoop jar /export/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar wordcount /user/you/input /user/you/output\n",
    "```\n",
    "\n",
    "- Remove the output directory and try to use yarn\n",
    "\n",
    "```bash\n",
    "yarn jar /export/hadoop-2.7.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar wordcount /user/you/input /user/you/output\n",
    "```\n",
    "\n",
    "- Connect to the [Yarn web user interface](http://svmass2.mass.uhb.fr:8088/cluster) and read the logs carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Deploying the MapReduce Python code on Hadoop\n",
    "\n",
    "This Python must use the [Hadoop Streaming API](http://hadoop.apache.org/docs/stable/hadoop-streaming/HadoopStreaming.html) to pass data between our Map and Reduce code via Pythonâ€™s sys.stdin (standard input) and sys.stdout (standard output). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Map \n",
    "\n",
    "The following Python code read data from sys.stdin, split it into words and output a list of lines mapping words to their (intermediate) counts to sys.stdout. For every word it outputs <word> 1 tuples immediately. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%file mapper.py\n",
    "#!/usr/bin/env python3\n",
    "from __future__ import print_function # for python2 compatibility\n",
    "import sys, string\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "# input comes from standard input\n",
    "for line in sys.stdin:\n",
    "    line = line.strip().lower() # remove leading and trailing whitespace\n",
    "    line = line.translate(translator)   # strip punctuation \n",
    "    for word in line.split(): # split the line into words\n",
    "        # write the results to standard output;\n",
    "        # what we output here will be the input for the\n",
    "        # Reduce step, i.e. the input for reducer.py\n",
    "        # tab-delimited; the trivial word count is 1\n",
    "        print (f'{word}\\t 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The python script must be executable:\n",
    "    \n",
    "```bash\n",
    "chmod +x mapper.py \n",
    "```\n",
    "\n",
    "Try to run in a terminal with:\n",
    "```bash\n",
    "cat sample01.txt | ./mapper.py | sort\n",
    "```\n",
    "or\n",
    "```bash\n",
    "./mapper.py < sample01.txt | sort\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adipisci\t 1\n",
      "adipisci\t 1\n",
      "adipisci\t 1\n",
      "adipisci\t 1\n",
      "adipisci\t 1\n",
      "adipisci\t 1\n",
      "adipisci\t 1\n",
      "adipisci\t 1\n",
      "aliquam\t 1\n",
      "aliquam\t 1\n",
      "aliquam\t 1\n",
      "aliquam\t 1\n",
      "aliquam\t 1\n",
      "aliquam\t 1\n",
      "aliquam\t 1\n",
      "aliquam\t 1\n",
      "aliquam\t 1\n",
      "aliquam\t 1\n",
      "aliquam\t 1\n",
      "aliquam\t 1\n",
      "aliquam\t 1\n",
      "amet\t 1\n",
      "amet\t 1\n",
      "amet\t 1\n",
      "amet\t 1\n",
      "amet\t 1\n",
      "amet\t 1\n",
      "amet\t 1\n",
      "amet\t 1\n",
      "amet\t 1\n",
      "amet\t 1\n",
      "consectetur\t 1\n",
      "consectetur\t 1\n",
      "consectetur\t 1\n",
      "consectetur\t 1\n",
      "consectetur\t 1\n",
      "consectetur\t 1\n",
      "dolor\t 1\n",
      "dolor\t 1\n",
      "dolor\t 1\n",
      "dolor\t 1\n",
      "dolor\t 1\n",
      "dolor\t 1\n",
      "dolor\t 1\n",
      "dolor\t 1\n",
      "dolor\t 1\n",
      "dolor\t 1\n",
      "dolor\t 1\n",
      "dolor\t 1\n",
      "dolore\t 1\n",
      "dolore\t 1\n",
      "dolore\t 1\n",
      "dolore\t 1\n",
      "dolore\t 1\n",
      "dolore\t 1\n",
      "dolore\t 1\n",
      "dolore\t 1\n",
      "dolore\t 1\n",
      "dolore\t 1\n",
      "dolore\t 1\n",
      "dolorem\t 1\n",
      "dolorem\t 1\n",
      "dolorem\t 1\n",
      "dolorem\t 1\n",
      "dolorem\t 1\n",
      "dolorem\t 1\n",
      "dolorem\t 1\n",
      "dolorem\t 1\n",
      "dolorem\t 1\n",
      "dolorem\t 1\n",
      "dolorem\t 1\n",
      "dolorem\t 1\n",
      "dolorem\t 1\n",
      "eius\t 1\n",
      "eius\t 1\n",
      "eius\t 1\n",
      "eius\t 1\n",
      "eius\t 1\n",
      "eius\t 1\n",
      "eius\t 1\n",
      "eius\t 1\n",
      "eius\t 1\n",
      "eius\t 1\n",
      "est\t 1\n",
      "est\t 1\n",
      "est\t 1\n",
      "est\t 1\n",
      "est\t 1\n",
      "est\t 1\n",
      "est\t 1\n",
      "est\t 1\n",
      "est\t 1\n",
      "est\t 1\n",
      "est\t 1\n",
      "est\t 1\n",
      "est\t 1\n",
      "etincidunt\t 1\n",
      "etincidunt\t 1\n",
      "etincidunt\t 1\n",
      "etincidunt\t 1\n",
      "etincidunt\t 1\n",
      "etincidunt\t 1\n",
      "etincidunt\t 1\n",
      "etincidunt\t 1\n",
      "etincidunt\t 1\n",
      "ipsum\t 1\n",
      "ipsum\t 1\n",
      "ipsum\t 1\n",
      "ipsum\t 1\n",
      "ipsum\t 1\n",
      "ipsum\t 1\n",
      "ipsum\t 1\n",
      "ipsum\t 1\n",
      "labore\t 1\n",
      "labore\t 1\n",
      "labore\t 1\n",
      "labore\t 1\n",
      "labore\t 1\n",
      "labore\t 1\n",
      "magnam\t 1\n",
      "magnam\t 1\n",
      "magnam\t 1\n",
      "magnam\t 1\n",
      "magnam\t 1\n",
      "magnam\t 1\n",
      "magnam\t 1\n",
      "magnam\t 1\n",
      "magnam\t 1\n",
      "modi\t 1\n",
      "modi\t 1\n",
      "modi\t 1\n",
      "modi\t 1\n",
      "modi\t 1\n",
      "modi\t 1\n",
      "modi\t 1\n",
      "modi\t 1\n",
      "modi\t 1\n",
      "modi\t 1\n",
      "modi\t 1\n",
      "neque\t 1\n",
      "neque\t 1\n",
      "neque\t 1\n",
      "neque\t 1\n",
      "neque\t 1\n",
      "neque\t 1\n",
      "neque\t 1\n",
      "neque\t 1\n",
      "neque\t 1\n",
      "neque\t 1\n",
      "neque\t 1\n",
      "non\t 1\n",
      "non\t 1\n",
      "non\t 1\n",
      "non\t 1\n",
      "non\t 1\n",
      "non\t 1\n",
      "non\t 1\n",
      "non\t 1\n",
      "non\t 1\n",
      "non\t 1\n",
      "non\t 1\n",
      "numquam\t 1\n",
      "numquam\t 1\n",
      "numquam\t 1\n",
      "numquam\t 1\n",
      "numquam\t 1\n",
      "numquam\t 1\n",
      "numquam\t 1\n",
      "numquam\t 1\n",
      "numquam\t 1\n",
      "numquam\t 1\n",
      "numquam\t 1\n",
      "porro\t 1\n",
      "porro\t 1\n",
      "porro\t 1\n",
      "porro\t 1\n",
      "porro\t 1\n",
      "porro\t 1\n",
      "porro\t 1\n",
      "quaerat\t 1\n",
      "quaerat\t 1\n",
      "quaerat\t 1\n",
      "quaerat\t 1\n",
      "quaerat\t 1\n",
      "quaerat\t 1\n",
      "quaerat\t 1\n",
      "quaerat\t 1\n",
      "quaerat\t 1\n",
      "quaerat\t 1\n",
      "quaerat\t 1\n",
      "quaerat\t 1\n",
      "quaerat\t 1\n",
      "quiquia\t 1\n",
      "quiquia\t 1\n",
      "quiquia\t 1\n",
      "quiquia\t 1\n",
      "quiquia\t 1\n",
      "quiquia\t 1\n",
      "quiquia\t 1\n",
      "quiquia\t 1\n",
      "quiquia\t 1\n",
      "quisquam\t 1\n",
      "quisquam\t 1\n",
      "quisquam\t 1\n",
      "quisquam\t 1\n",
      "quisquam\t 1\n",
      "quisquam\t 1\n",
      "quisquam\t 1\n",
      "quisquam\t 1\n",
      "quisquam\t 1\n",
      "quisquam\t 1\n",
      "sed\t 1\n",
      "sed\t 1\n",
      "sed\t 1\n",
      "sed\t 1\n",
      "sed\t 1\n",
      "sed\t 1\n",
      "sed\t 1\n",
      "sed\t 1\n",
      "sit\t 1\n",
      "sit\t 1\n",
      "sit\t 1\n",
      "sit\t 1\n",
      "sit\t 1\n",
      "sit\t 1\n",
      "sit\t 1\n",
      "sit\t 1\n",
      "sit\t 1\n",
      "sit\t 1\n",
      "tempora\t 1\n",
      "tempora\t 1\n",
      "tempora\t 1\n",
      "tempora\t 1\n",
      "tempora\t 1\n",
      "tempora\t 1\n",
      "tempora\t 1\n",
      "tempora\t 1\n",
      "tempora\t 1\n",
      "tempora\t 1\n",
      "tempora\t 1\n",
      "tempora\t 1\n",
      "ut\t 1\n",
      "ut\t 1\n",
      "ut\t 1\n",
      "ut\t 1\n",
      "ut\t 1\n",
      "ut\t 1\n",
      "velit\t 1\n",
      "velit\t 1\n",
      "velit\t 1\n",
      "velit\t 1\n",
      "velit\t 1\n",
      "velit\t 1\n",
      "velit\t 1\n",
      "velit\t 1\n",
      "velit\t 1\n",
      "velit\t 1\n",
      "velit\t 1\n",
      "velit\t 1\n",
      "velit\t 1\n",
      "velit\t 1\n",
      "voluptatem\t 1\n",
      "voluptatem\t 1\n",
      "voluptatem\t 1\n",
      "voluptatem\t 1\n",
      "voluptatem\t 1\n",
      "voluptatem\t 1\n",
      "voluptatem\t 1\n",
      "voluptatem\t 1\n",
      "voluptatem\t 1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "chmod +x mapper.py\n",
    "cat sample01.txt | ./mapper.py | sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reduce \n",
    "\n",
    "The following code reads the results of mapper.py and sum the occurrences of each word to a final count, and then output its results to sys.stdout.\n",
    "Remember that Hadoop sorts map output so it is easier to count words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%file reducer.py\n",
    "#!/usr/bin/env python3\n",
    "from __future__ import print_function\n",
    "from operator import itemgetter\n",
    "import sys\n",
    "\n",
    "current_word = None\n",
    "current_count = 0\n",
    "word = None\n",
    "\n",
    "for line in sys.stdin:\n",
    "    \n",
    "    # parse the input we got from mapper.py\n",
    "    word, count = line.split('\\t', 1)\n",
    "\n",
    "    # convert count (currently a string) to int\n",
    "    try:\n",
    "        count = int(count)\n",
    "    except ValueError:\n",
    "        # count was not a number, so silently\n",
    "        # ignore/discard this line\n",
    "        continue\n",
    "\n",
    "    # this IF-switch only works because Hadoop sorts map output\n",
    "    # by key (here: word) before it is passed to the reducer\n",
    "    if current_word == word:\n",
    "        current_count += count\n",
    "    else:\n",
    "        if current_word:\n",
    "            # write result to sys.stdout\n",
    "            print (f'{current_count}\\t{current_word}')\n",
    "        current_count = count\n",
    "        current_word = word\n",
    "\n",
    "# do not forget to output the last word if needed!\n",
    "if current_word == word:\n",
    "    print (f'{current_count}\\t{current_word}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As mapper the python script must be executable:\n",
    "    \n",
    "```bash\n",
    "chmod +x reducer.py \n",
    "```\n",
    "\n",
    "Try to run in a terminal with:\n",
    "```bash\n",
    "cat sample.txt | ./mapper.py | sort | ./reducer.py | sort\n",
    "```\n",
    "or\n",
    "```bash\n",
    "./mapper.py < sample01.txt | sort | ./reducer.py | sort\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\tamet\n",
      "10\teius\n",
      "10\tquisquam\n",
      "10\tsit\n",
      "11\tdolore\n",
      "11\tmodi\n",
      "11\tneque\n",
      "11\tnon\n",
      "11\tnumquam\n",
      "12\tdolor\n",
      "12\ttempora\n",
      "13\taliquam\n",
      "13\tdolorem\n",
      "13\test\n",
      "13\tquaerat\n",
      "14\tvelit\n",
      "6\tconsectetur\n",
      "6\tlabore\n",
      "6\tut\n",
      "7\tporro\n",
      "8\tadipisci\n",
      "8\tipsum\n",
      "8\tsed\n",
      "9\tetincidunt\n",
      "9\tmagnam\n",
      "9\tquiquia\n",
      "9\tvoluptatem\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "chmod +x reducer.py \n",
    "./mapper.py < sample01.txt | sort | ./reducer.py | sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Execution on Hadoop cluster\n",
    "\n",
    "* Copy all files to HDFS cluster\n",
    "* Run the WordCount MapReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Makefile\n"
     ]
    }
   ],
   "source": [
    "%%file Makefile\n",
    "\n",
    "HADOOP_VERSION=2.7.6\n",
    "HADOOP_HOME=/export/hadoop-${HADOOP_VERSION}\n",
    "HADOOP_TOOLS=${HADOOP_HOME}/share/hadoop/tools/lib\n",
    "HDFS_DIR=/user/${USER}\n",
    "\n",
    "SAMPLES = sample01.txt sample02.txt sample03.txt sample04.txt\n",
    "\n",
    "copy_to_hdfs: ${SAMPLES}\n",
    "\thdfs dfs -mkdir -p ${HDFS_DIR}/input\n",
    "\thdfs dfs -put $^ ${HDFS_DIR}/input\n",
    "\n",
    "run_with_hadoop: \n",
    "\thadoop jar ${HADOOP_TOOLS}/hadoop-streaming-${HADOOP_VERSION}.jar \\\n",
    "    -file  ${PWD}/mapper.py  -mapper  ${PWD}/mapper.py \\\n",
    "    -file  ${PWD}/reducer.py -reducer ${PWD}/reducer.py \\\n",
    "    -input ${HDFS_DIR}/input/*.txt -output ${HDFS_DIR}/output-hdfs\n",
    "\n",
    "run_with_yarn: \n",
    "\tyarn jar ${HADOOP_TOOLS}/hadoop-streaming-${HADOOP_VERSION}.jar \\\n",
    "\t-file  ${PWD}/mapper.py  -mapper  ${PWD}/mapper.py \\\n",
    "\t-file  ${PWD}/reducer.py -reducer ${PWD}/reducer.py \\\n",
    "\t-input ${HDFS_DIR}/input/*.txt -output ${HDFS_DIR}/output-yarn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yarn jar /export/hadoop-2.7.6/share/hadoop/tools/lib/hadoop-streaming-2.7.6.jar/hadoop-streaming-2.7.6.jar \\\n",
      "\t-file  /Users/navaro/PycharmProjects/big-data/notebooks/mapper.py  -mapper  /Users/navaro/PycharmProjects/big-data/notebooks/mapper.py \\\n",
      "\t-file  /Users/navaro/PycharmProjects/big-data/notebooks/reducer.py -reducer /Users/navaro/PycharmProjects/big-data/notebooks/reducer.py \\\n",
      "\t-input /user/navaro/input/*.txt -output /user/navaro/output-yarn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Not a valid JAR: /export/hadoop-2.7.6/share/hadoop/tools/lib/hadoop-streaming-2.7.6.jar/hadoop-streaming-2.7.6.jar\n",
      "make: *** [run_with_yarn] Error 255\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "make run_with_yarn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
