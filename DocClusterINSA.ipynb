{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Connexion au cluster\n",
    "\n",
    "La connexion est possible uniquement depuis les PCs des salles de TP  \n",
    "\n",
    "```bash\n",
    "$ ssh pnavaro@cluster-infomaths.insa-rennes.fr\n",
    "The authenticity of host 'cluster-infomaths.insa-rennes.fr (193.52.94.112)' can't be established.\n",
    "ECDSA key fingerprint is SHA256:wEtf2Oc8PKFls/D9oDQF4vXcs9y2ku0i+At4KiVJ04Q.\n",
    "Are you sure you want to continue connecting (yes/no)? yes\n",
    "Warning: Permanently added 'cluster-infomaths.insa-rennes.fr,193.52.94.112' (ECDSA) to the list of known hosts.\n",
    "pnavaro@cluster-infomaths.insa-rennes.fr's password:\n",
    "Linux cim-tete 4.9.0-4-amd64 #1 SMP Debian 4.9.65-3+deb9u1 (2017-12-23) x86_64\n",
    "\n",
    "The programs included with the Debian GNU/Linux system are free software;\n",
    "the exact distribution terms for each program are described in the\n",
    "individual files in /usr/share/doc/*/copyright.\n",
    "\n",
    "Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent\n",
    "permitted by applicable law.\n",
    "Last login: Tue Oct 16 09:02:56 2018 from 10.4.1.36\n",
    "pnavaro@cim-tete:~$ \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Commandes de base\n",
    "\n",
    "- **sbatch**  : soumission d'un job dans une partition.\n",
    "- **scancel** : Suppression d'un job.\n",
    "- **squeue**  : interrogation des jobs.\n",
    "- **sinfo**   : interrogation des files d'attente.\n",
    "- **srun**    : execution immediate d'une commande.\n",
    "- **salloc**  : batch interactif, obtention d'un shell, permettant d'enchaîner plusieurs commandes sur les mêmes ressources.  \n",
    "- **sprio**   : priorités relatives entre les jobs en attente  \n",
    "\n",
    "Une documentation des commandes de base est disponible ici : [http://slurm.schedmd.com/man_index.html](http://slurm.schedmd.com/man_index.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Utilisation du Cluster\n",
    "\n",
    "## Ressources disponibles\n",
    "\n",
    "- **Noeuds :** 4 (cim-n01 / cim-n02 / cim-n03 / cim-n04)  \n",
    "- **CPU par noeud :** 24  \n",
    "- **Socket par noeud :** 1  \n",
    "- **Coeur par socket :** 12  \n",
    "- **Threads par coeur :** 2  \n",
    "- **RAM par noeud :** 64Go  \n",
    "- **Nom du cluster :** cluster-infomath  \n",
    "- **Nom de la partition :** queue "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lancement d'un job\n",
    "\n",
    "Pour lancer un job, il faut créer un script dans lequel il faut demander des ressources puis appeler son programme (voir les exemples plus loin).  \n",
    "\n",
    "Ce script est ensuite soumi au gestionnaire de file d'attente avec la commande **sbatch**. Par exemple :  \n",
    "\n",
    "```\n",
    "$ sbatch mon_script.sh\n",
    "```\n",
    "\n",
    "On obtient alors un numéro de job, qui peut être manipulé avec les commandes `scancel` ou `squeue`.  \n",
    "\n",
    "Le script peut être écrit dans le langage de son choix (bash, tcsh, python, perl...). Il peut être exécuté directement, sans être appelé par sbatch, et dans ce cas, les directives d'allocations de ressources seront ignorées, et il s'exécutera dans le shell local.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`\n",
    "## Demande de ressources\n",
    "\n",
    "Vos besoins en terme de ressources sont décrits dans l'en-tête d'un fichier via des directives Slurm. Par exemple :  \n",
    "\n",
    "```slurm\n",
    "#SBATCH -N 4  \n",
    "#SBATCH --tasks-per-node 5\n",
    "```\n",
    "\n",
    "demandera une allocation de 4 noeuds à 5 coeurs chacun (par défaut, 1 tâche demande 1 coeur)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "D'autres critères peuvent être spécifié via ces directives, comme la taille mémoire souhaitée ou la durée pendant laquelle les ressources seront attribuées.  \n",
    "\n",
    "**Plus vous serez parcimonieux dans la demande d'allocation, plus vous aurez de chance de voir rapidement votre job passer de l'état en attente à l'état en exécution.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Par exemple, s'il est possible d'estimer précisément la durée nécessaire à une exécution, il peut être profitable de réduire au minimum la durée demandée pour la réservation. Ainsi une exécution se faisant en 3h30 pourra se faire au sein d'un job demandant 4h00 (marge de 30mn par précaution), avec la directive  \n",
    "\n",
    "```\n",
    "#SBATCH -t 04:00:00  \n",
    "```\n",
    "\n",
    "Attention toutefois à prendre une marge suffisante, car au-delà du temps demandé, l'exécution est stoppée automatiquement par Slurm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Attention : toutes les partitions sont configurées avec une limite de temps d'exécution par défaut, qui s'applique à tout job ne précisant pas combien de temps doit lui être alloué. Pour connaître cette limite, utiliser la commande suivante :  \n",
    "\n",
    "```\n",
    "sinfo -o \"%10P %.11L %.11l\"\n",
    "```\n",
    "\n",
    "Remarque : tous les arguments de la directive #SBATCH peuvent également être utilisés en arguments des commandes srun, salloc et sbatch. Voir les exemples plus loin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Suivre l'état d'un job\n",
    "\n",
    "Il est possible d'obtenir le détail de l'état d'un job, qu'il soit en attente ou en exécution, avec les commandes scontrol ou squeue. La commande sview permet également en partie d'obtenir ces informations.  \n",
    "\n",
    "**Liste des jobs en cours :**  \n",
    "\n",
    "```\n",
    "squeue -u\n",
    "```\n",
    "\n",
    "**Détail de l'état d'un job :**\n",
    "\n",
    "```\n",
    "show job\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Mon job est en attente. Quand va-t-il démarrer ?**  \n",
    "\n",
    "Pour les jobs en attente, Slurm calcul périodiquement un temps probable de démarrage.  \n",
    "\n",
    "2 possibilités pour l'obtenir:  \n",
    "\n",
    "```\n",
    "scontrol show job <jobid>| grep StartTime=</jobid>\n",
    "```\n",
    "\n",
    "```\n",
    "squeue -o \"%S\" -j\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Variables d'environnement\n",
    "\n",
    "Dans certains cas, votre programme a besoin de connaître plus précisément les ressources que Slurm a mis à sa disposition. Pour cela, Slurm fourni un certain nombre de variables d'environnement, qui sont utilisable dans le script qui appelle le programme.  \n",
    "\n",
    "- SLURM_NPROCS : nombre de coeurs alloués  \n",
    "- SLURM_NNODES : nombre de noeuds alloués  \n",
    "- SLURM_JOB_ID : job id  \n",
    "- SLURM_JOB_NODELIST : liste des noeuds alloués, sous une forme synthétique. Pour obtenir une liste détaillée, on peut utiliser la commande \"scontrol show hostname\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Priorités\n",
    "\n",
    "Quand plusieurs jobs sont en même temps en attente dans une file, Slurm calcule une priorité entre ces jobs. Le job ayant la priorité la plus élevée sera le prochain à passer en exécution.  \n",
    "\n",
    "La priorité des jobs peut être vue avec la commande `sprio -l`.  \n",
    "\n",
    "La priorité dépend de plusieurs facteurs :  \n",
    "- le temps d'attente déjà écoulé (AGE)  \n",
    "- la taille du job en nombre de coeurs : les gros jobs sont favorisés (JOBSIZE)  \n",
    "- la consommation en heures cpu sur le passé récent : plus la consommation a été faible, plus la priorité augmentera (FAIRSHARE).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exemples\n",
    "\n",
    "## Exemple de script Slurm simple\n",
    "\n",
    "Ce script demande 36 coeurs répartis sur au minimum sur 3 noeuds et au maximum sur 6 noeuds :  \n",
    "\n",
    "```bash\n",
    "#! /bin/bash  \n",
    "#SBATCH -p public  \n",
    "#SBATCH -A lol # voir chapitre \"Autorisations / Account\" ci-dessus  \n",
    "#SBATCH -n 36 # 36 coeurs  \n",
    "#SBATCH -N 3-6 # au minimum 3 noeuds, au maximum 6  \n",
    "#SBATCH -t 12:00:00 # Le job sera tué au bout de 12h  \n",
    "#SBATCH --mem=1024 # Quantité mémoire demandée par noeud en Mo (unité obligatoire)  \n",
    "#SBATCH --mail-type=END # Réception d'un mail à la fin du job  \n",
    "#SBATCH --mail-user=mon@adresse  \n",
    "\n",
    "mpirun mon_code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exemple de script Slurm \n",
    "\n",
    "- Spécification de la répartition des tâches par noeud\n",
    "\n",
    "Si vous avez besoin d’indiquer exactement la répartition des tâches sur les noeuds, vous pouvez utiliser tout ou partie des paramètres `--tasks-per-node`, `--distribution` et éventuellement `--cpu_bind` pour avoir un état de la répartition.  \n",
    "\n",
    "Vous pouvez par exemple demander 4 coeurs par noeud sur 3 noeuds, avec une répartition cyclique des tâches sur les noeuds, cad la 1ère tâche sur le noeud 1, la 2nd sur le 2nd noeud, la 3ème sur le 3ème noeud, puis la 4ème sur le 1er noeud et ainsi de suite :  \n",
    "\n",
    "```bash\n",
    "#!/bin/bash  \n",
    "#SBATCH -p grant  \n",
    "#SBATCH -A grant18 # voir chapitre \"Autorisations / Account\" ci-dessus  \n",
    "#SBATCH -N 3 # 3 noeuds  \n",
    "#SBATCH --tasks-per-node=4 # 4 tâches par noeud (par défaut 1 tâche = 1 coeur)  \n",
    "# La répartition par défaut des tâches est de type block, cad toutes les tâches du début  \n",
    "# sur le 1er noeud, les tâches suivantes sur le 2nd, etc.. :  \n",
    "#SBATCH --distribution=cyclic  \n",
    "#SBATCH --cpu_bind=verbose # produira un état donnant la correspondance tâche/noeud/coeur  \n",
    "\n",
    "# Environnement par défaut : contient les compilateurs Intel 11  \n",
    "source /home/configfiles/bashrc.default  \n",
    "\n",
    "# On remplace par le compilateur Intel 13  \n",
    "module delete compilers/intel11  \n",
    "module load compilers/intel13  \n",
    "\n",
    "# Ajoutons OpenMPI  \n",
    "module load mpi/openmpi-1.6.i13  \n",
    "\n",
    "# Ajoutons les lib math. Intel  \n",
    "module load libs/mkl13  \n",
    "\n",
    "# Enfin, lançons simplement le job  \n",
    "# le mpirun de openmpi est interfacé nativement avec Slurm  \n",
    "# Ainsi, nul besoin de préciser le nombre de processeurs et la liste  \n",
    "# des machines  \n",
    "cd ${HOME}/somewhere_i_want_to_work  \n",
    "mpirun my_mpi_executable  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exemple de demande de ressources\n",
    "\n",
    "Les commandes srun, salloc, sbatch peuvent prendre les même paramètres que ceux de la directive #SBATCH.  \n",
    "\n",
    "Par exemple, la commande suivante demandera 4 coeurs et lancera 1 fois par coeur la commande hostname  \n",
    "\n",
    "```\n",
    "$ srun -n 4 hostname  \n",
    "cim-n01  \n",
    "cim-n01  \n",
    "cim-n01  \n",
    "cim-n01\n",
    "```\n",
    "\n",
    "Autre exemple en précisant la répartition :  \n",
    "\n",
    "```\n",
    "$ srun -n 4 --tasks-per-node=2 hostname  \n",
    "cim-n01  \n",
    "cim-n01  \n",
    "cim-n02  \n",
    "cim-n02  \n",
    "```\n",
    "\n",
    "Exemple avec la commande salloc, qui permet de travailler en interactif dans une réservation. Demandons 32 coeurs :  \n",
    "\n",
    "```\n",
    "$ salloc -n 32  \n",
    "salloc: Granted job allocation 472  \n",
    "$  \n",
    "```\n",
    "\n",
    "On pourrait avoir l'impression qu'il ne s'est rien passé, cependant :  \n",
    "\n",
    "- en pratique, les ressources ont été réservées  \n",
    "dans l'environnement du shell crée, Slurm a positionné des variables qui indiqueront aux jobs parallèles (MPI, Slurm) les ressources à utiliser Par exemple, la commande srun hostname (lancée dans le shell précédemment obtenu), produira la sortie suivante :  \n",
    "\n",
    "```$ srun hostname  \n",
    "cim-n01  \n",
    "cim-n01  \n",
    "... (24 fois)  \n",
    "cim-n02  \n",
    "cim-n02  \n",
    "... (8 fois)  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exemple de lancement d'un job MPI\n",
    "\n",
    "OpenMPI est couplé nativement avec Slurm. Par défaut, il lancera autant de processus que de coeurs disponibles.  \n",
    "\n",
    "Il est possible d'éviter que les processus MPI se déplacent d'un coeur à l'autre par l'option --bind-to-core de mpirun  \n",
    "\n",
    "Pour les applications mpi hybrides (X processus lançant chacun Y threads), il faut :  \n",
    "- réserver X*Y coeurs avec slurm, en indiquant qu'on prend tous les coeurs d'un noeud (--tasks-per-node=16)  \n",
    "- lancer mpirun -npernode 2 -bind-to-socket -npersocket 1 mon_code  \n",
    "- mpirun obtient la liste des machines de slurm  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exemple de lancement d'un job OpenMP\n",
    "\n",
    "Par défaut les threads des jobs OpenMP seront regroupés de manière compacte sur les coeurs d'un même socket.  \n",
    "\n",
    "Par exemple, pour soumettre un job OpenMP sur 16 coeurs et dans un script, les commandes seraient les suivantes :  \n",
    "\n",
    "```bash\n",
    "#! /bin/bash  \n",
    "\n",
    "#SBATCH -n 16 --tasks-per-node=16  \n",
    "\n",
    "export OMP_NUM_THREADS=16  \n",
    "\n",
    "./mon_code_omp\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exemple de lancement d'un job hybride MPI/OpenMP\n",
    "\n",
    "Pour exécuter par exemple 8 tâches MPI lançant chacune 4 thread OpenMP, il faut un total de 32 coeurs  \n",
    "\n",
    "Tout d'abord, il faut indiquer dans le script le nombre de threads OpenMP que doit lancer chaque process MPI : \n",
    "\n",
    "```bash\n",
    "export OMP_NUM_THREADS=4\n",
    "```\n",
    "\n",
    "Ensuite, chaque tâche MPI aura besoin de 4 coeurs obligatoirement sur le même noeud (pour que chaque thread OpenMP ait son propre coeur). Il faut donc faire une des demandes de ressources suivantes à Slurm :  \n",
    "Pour obtenir 8 noeuds différents avec 4 coeurs chacun :  \n",
    "\n",
    "```bash\n",
    "#SBATCH --tasks-per-node=4  \n",
    "#SBATCH -N 8  \n",
    "```\n",
    "\n",
    "ou alors 4 noeuds différents avec 8 coeurs (version adaptée aux noeuds 8 coeurs de la partition pri2008)  \n",
    "\n",
    "```bash\n",
    "#SBATCH --tasks-per-node=8  \n",
    "#SBATCH -N 4  \n",
    "```\n",
    "\n",
    "ou encore 2 noeuds différents avec 16 coeurs (version adaptée aux noeuds Equip@meso 16 coeurs)  \n",
    "\n",
    "```bash\n",
    "#SBATCH --tasks-per-node=16  \n",
    "#SBATCH -N 2  \n",
    "```\n",
    "\n",
    "Enfin, lors du lancement du programme par mpirun, il faut également indiquer le nombre de tâches qu'il faut lancer par noeud, à l'aide de l'option **-npernode** ainsi que le nombre de tâches par socket avec **-npersocket**. Cette dernière option est très importante, car les thread OpenMP lancés par un processus MPI sont toujours localisés sur le même socket que celui sur lequel tourne le process MPI.  \n",
    "\n",
    "Par exemple, pour le cas 2 ci-dessus, sur 4 noeuds, on lance 2 tâches MPI par noeud, 1 par socket :  \n",
    "\n",
    "```bash\n",
    "mpirun -npernode 2 -npersocket 1 mon_programme\n",
    "```\n",
    "\n",
    "ou pour le cas 3 ci-dessus, sur 2 noeuds, on lance 4 tâches MPI par noeud, 2 par socket :  \n",
    "\n",
    "```\n",
    "mpirun -npernode 4 -npersocket 2 mon_programme\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INSA Rennes / Département INFO © 2017**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
